### Landing Page Screen

Command by user: given this user journey generate me some wireframes, I only need the 2, the First page where they select the filepath, and the second where there is a video and a OCR boxSetup:1. Clone repo → 2. Run FastAPI/web GUI → 3. Provide video path ↓Playback:4. App announces "Loaded. Duration 13m42s. Press Space to play..." ↓Interaction:5. John plays/pauses → presses OCR shortcut for current frame ↓Processing:6. App: "Recognizing text..." → queries API with frame time ↓Output:7. App displays OCR text → JAWS reads it aloud ↓Next actions:8. John resumes playback or saves/export OCR results

UX PILOT agent

### OCR Page Screen

Command by user: given this user journey generate me some wireframes, I only need the 2, the First page where they select the filepath, and the second where there is a video and a OCR boxSetup:1. Clone repo → 2. Run FastAPI/web GUI → 3. Provide video path ↓Playback:4. App announces "Loaded. Duration 13m42s. Press Space to play..." ↓Interaction:5. John plays/pauses → presses OCR shortcut for current frame ↓Processing:6. App: "Recognizing text..." → queries API with frame time ↓Output:7. App displays OCR text → JAWS reads it aloud ↓Next actions:8. John resumes playback or saves/export OCR results

UX PILOT agent
